{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Introduction Colab + Tensors","provenance":[{"file_id":"10CS0xWwZCPKe02VlvPFIaskvquvUCQby","timestamp":1587704350433}],"collapsed_sections":["-d3JEthF_Z34","1k78bS8J_z_X","LSfVOBMhAXw5","vzSaCU7VBIKO","u8UPrkx1BzL0","S5wlHjtfD_UZ","Zr1JaKxJB_QQ"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5292665001f74267b1acf04179610c34":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","state":{"_view_name":"VBoxView","_dom_classes":["widget-interact"],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_338b70a4f0434947a4fef1f05441b24c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6b1a062e708a4693a25c4f5c1657aad6","IPY_MODEL_d61151c877904c38843926a6d0f9f96f"]}},"338b70a4f0434947a4fef1f05441b24c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6b1a062e708a4693a25c4f5c1657aad6":{"model_module":"@jupyter-widgets/controls","model_name":"IntSliderModel","state":{"_view_name":"IntSliderView","style":"IPY_MODEL_cc3449aec3c947afa0ecf431ce3d9f29","_dom_classes":[],"description":"n","step":1,"_model_name":"IntSliderModel","orientation":"horizontal","max":60000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":12103,"_view_count":null,"disabled":false,"_view_module_version":"1.5.0","min":0,"continuous_update":true,"readout_format":"d","description_tooltip":null,"readout":true,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f35eee3c086c491cb5c999b36dc6aa3f"}},"d61151c877904c38843926a6d0f9f96f":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","state":{"_view_name":"OutputView","msg_id":"","_dom_classes":[],"_model_name":"OutputModel","outputs":[{"output_type":"display_data","metadata":{"tags":[],"needs_background":"light"},"image/png":"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\n","text/plain":"<Figure size 432x288 with 1 Axes>"}],"_view_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_view_count":null,"_view_module_version":"1.0.0","layout":"IPY_MODEL_d1ab6f2a1bae48c4b5582fbed90a27d9","_model_module":"@jupyter-widgets/output"}},"cc3449aec3c947afa0ecf431ce3d9f29":{"model_module":"@jupyter-widgets/controls","model_name":"SliderStyleModel","state":{"_view_name":"StyleView","handle_color":null,"_model_name":"SliderStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f35eee3c086c491cb5c999b36dc6aa3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d1ab6f2a1bae48c4b5582fbed90a27d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"ij9d1oPbWJRt","colab_type":"text"},"source":["# 392028 Introduction to Neural Networks\n","Copyright 2020 - Riza Velioglu, Bielefeld University"]},{"cell_type":"markdown","metadata":{"id":"BtTSlB-GSwF7","colab_type":"text"},"source":["# I. Introduction to Google Colab\n","\n","Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud.\n","\n","With Colaboratory you can write and execute code, save and share your analyses, and access powerful computing resources, all for free from your browser. See the [video](https://www.youtube.com/watch?v=inN8seMm7UI) to get an overview of the key features of Colaboratory.\n","The document you are reading is a  [Jupyter notebook](https://jupyter.org/), hosted in Colaboratory. It is not a static page, but an interactive environment that lets you write and execute code in Python and other languages.\n","\n","For example, here is a **code cell** with a short Python script that computes a value, stores it in a variable, and prints the result:"]},{"cell_type":"code","metadata":{"id":"V000Hk3HljXt","colab_type":"code","outputId":"e35535b6-ea03-4184-96ad-ca1a7f9a199f","executionInfo":{"status":"ok","timestamp":1586010412174,"user_tz":-120,"elapsed":840,"user":{"displayName":"rıza velioğlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI3dzxfFyTp2bxbRrt27r2hA8TXG92kFr6_ZmPwg=s64","userId":"10695532619357753233"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["seconds_in_a_day = 24 * 60 * 60\n","seconds_in_a_day"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["86400"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"LLDmkjcmle47","colab_type":"text"},"source":["To execute the code in the above cell, select it with a click and then either press the play button to the left of the code, or use the keyboard shortcut \"Command/Ctrl+Enter\".\n","\n","All cells modify the same global state, so variables that you define by executing a cell can be used in other cells:"]},{"cell_type":"code","metadata":{"id":"zMFMiA-2ca3K","colab_type":"code","outputId":"220a0a4d-e590-43d7-fc9f-265fb6202c22","executionInfo":{"status":"ok","timestamp":1586008028529,"user_tz":-120,"elapsed":598,"user":{"displayName":"rıza velioğlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI3dzxfFyTp2bxbRrt27r2hA8TXG92kFr6_ZmPwg=s64","userId":"10695532619357753233"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["seconds_in_a_week = 7 * seconds_in_a_day\n","seconds_in_a_week"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["604800"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"3ra1FX_DdBMn","colab_type":"text"},"source":["What does Colab offer?\n","- Zero configuration required\n","- Easy sharing\n","- Clone GitHub repositories\n","- Import/Share notebooks from Drive\n","- Import external datasets, e.g.from Kaggle\n","- Integrate PyTorch, TensorFlow, Keras, OpenCV\n","- Free access to GPUs!!\n","\n","To get more about Colaboratory check the following tutorials:\n","- [Google Colaboratory](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)\n","- [Tutorialspoint](https://www.tutorialspoint.com/google_colab/index.htm)\n","\n","> If you would like install Keras and its dependencies on your local computer, please follow the step-by-step guide here: https://livebook.manning.com/book/deep-learning-with-python/appendix-a/"]},{"cell_type":"markdown","metadata":{"id":"oSmDKslcGbNN","colab_type":"text"},"source":["---\n","## A little more on Colab"]},{"cell_type":"markdown","metadata":{"id":"u_hUFqHtHaqz","colab_type":"text"},"source":["- Installing packages\n","- Cloning GitHub repositories\n","- Mounting Google Drive\n","- Changing the Hardware Accelerator\n","- Importing Datasets (Kaggle, Drive, GitHub, etc.)"]},{"cell_type":"code","metadata":{"id":"nU1N3fIvGab-","colab_type":"code","colab":{}},"source":["!pip install Keras"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_2J3p0ACHqe7","colab_type":"code","outputId":"4347f9e7-6f81-4417-8ff5-f73bda8b0341","executionInfo":{"status":"ok","timestamp":1587646874121,"user_tz":-120,"elapsed":5242,"user":{"displayName":"rıza velioğlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI3dzxfFyTp2bxbRrt27r2hA8TXG92kFr6_ZmPwg=s64","userId":"10695532619357753233"}},"colab":{"base_uri":"https://localhost:8080/","height":98}},"source":["!git clone https://github.com/keras-team/keras"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'keras'...\n","remote: Enumerating objects: 32987, done.\u001b[K\n","remote: Total 32987 (delta 0), reused 0 (delta 0), pack-reused 32987\u001b[K\n","Receiving objects: 100% (32987/32987), 13.11 MiB | 23.88 MiB/s, done.\n","Resolving deltas: 100% (24100/24100), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ixDPpz6fIW8J","colab_type":"code","outputId":"fc90e7ac-5522-444e-c59e-a3977b99e9a0","executionInfo":{"status":"ok","timestamp":1587646923044,"user_tz":-120,"elapsed":3084,"user":{"displayName":"rıza velioğlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI3dzxfFyTp2bxbRrt27r2hA8TXG92kFr6_ZmPwg=s64","userId":"10695532619357753233"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["keras  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lXeyWdBxIUBb","colab_type":"code","outputId":"2fb125f9-bd1d-479c-892d-e9910e720246","executionInfo":{"status":"ok","timestamp":1587646941537,"user_tz":-120,"elapsed":3417,"user":{"displayName":"rıza velioğlu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI3dzxfFyTp2bxbRrt27r2hA8TXG92kFr6_ZmPwg=s64","userId":"10695532619357753233"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["import os\n","os.chdir(\"keras\")\n","!pwd"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/keras\n"],"name":"stdout"}]},{"source":["### Specifying the TensorFlow version\n","\n","Running `import tensorflow` will import the default version (currently 2.x). You can use 1.x by running a cell with the `tensorflow_version` magic **before** you run `import tensorflow`."],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["UsageError: Line magic function `%tensorflow_version` not found.\n"]}],"source":["%tensorflow_version 1.x\n","import tensorflow\n","print(tensorflow.__version__)"]},{"cell_type":"markdown","metadata":{"id":"FM5QCDd8nLZy","colab_type":"text"},"source":["Further reading: [Introduction to Google Colab](https://colab.research.google.com/notebooks/welcome.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"-d3JEthF_Z34","colab_type":"text"},"source":["# II. Data representations for neural networks"]},{"cell_type":"markdown","metadata":{"id":"ROCoPdm0_eTh","colab_type":"text"},"source":["In general, all current machine-learning systems use tensors as their basic data structure. Tensors are fundamental to the field—so fundamental that Google’s TensorFlow was named after them. So what’s a tensor?\n","\n","At its core, a tensor is a container for data—almost always numerical data. So, it’s a container for numbers. You may be already familiar with matrices, which are 2D tensors: tensors are a generalization of matrices to an arbitrary number of dimensions (note that in the context of tensors, a dimension is often called an axis)."]},{"cell_type":"markdown","metadata":{"id":"1k78bS8J_z_X","colab_type":"text"},"source":["## **Scalars (0D Tensors)**"]},{"cell_type":"markdown","metadata":{"id":"AkDSaX-v_4pe","colab_type":"text"},"source":["A tensor that contains only one number is called a *scalar* (or scalar tensor, or 0-dimensional tensor, or 0D tensor). In Numpy, a `float32` or `float64` number is a scalar tensor (or scalar array). You can display the number of axes of a Numpy tensor via the `ndim` attribute; a scalar tensor has 0 axes (`ndim == 0`). The number of axes of a tensor is also called its `rank`. Here’s a Numpy scalar:"]},{"cell_type":"code","metadata":{"id":"8VW5mj6SkSos","colab_type":"code","outputId":"3ed5da77-fff3-4a0b-9ca1-68451981cdbe","executionInfo":{"status":"ok","timestamp":1587701235457,"user_tz":-120,"elapsed":2314,"user":{"displayName":"Robert Haschke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJN0g2mpV0fVJ3Sek5D40HuIwztiXftNdrsw-uaQ=s64","userId":"11038746730354035196"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["import numpy as np\n","x = np.array(12)\n","x"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(12)"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"_eyAwJ6XAV25","colab_type":"code","outputId":"2b955b03-159d-40d1-9022-d536fadf64c2","executionInfo":{"status":"ok","timestamp":1587701235458,"user_tz":-120,"elapsed":2290,"user":{"displayName":"Robert Haschke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJN0g2mpV0fVJ3Sek5D40HuIwztiXftNdrsw-uaQ=s64","userId":"11038746730354035196"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["x.ndim"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"LSfVOBMhAXw5","colab_type":"text"},"source":["## **Vectors (1D Tensors)**"]},{"cell_type":"markdown","metadata":{"id":"h0Mf_dO7AhjT","colab_type":"text"},"source":["An array of numbers is called a *vector*, or 1D tensor. A 1D tensor is said to have exactly one axis. Following is a Numpy vector:"]},{"cell_type":"code","metadata":{"id":"3H2If7RXAak3","colab_type":"code","outputId":"e5d73cc1-9d31-47f2-8bb0-95796f12f648","executionInfo":{"status":"ok","timestamp":1587701235459,"user_tz":-120,"elapsed":2285,"user":{"displayName":"Robert Haschke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJN0g2mpV0fVJ3Sek5D40HuIwztiXftNdrsw-uaQ=s64","userId":"11038746730354035196"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["x = np.array([12, 3, 6, 14])\n","x"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([12,  3,  6, 14])"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"Qyhwn7miAp_N","colab_type":"code","outputId":"2fdffcda-8361-4f23-dc4f-e30f2f4fb6da","executionInfo":{"status":"ok","timestamp":1587701235460,"user_tz":-120,"elapsed":2280,"user":{"displayName":"Robert Haschke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJN0g2mpV0fVJ3Sek5D40HuIwztiXftNdrsw-uaQ=s64","userId":"11038746730354035196"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["x.ndim"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"neKS7QKQAvZT","colab_type":"text"},"source":["This vector has five entries and so is called a *5-dimensional vector*. Don’t confuse a 5D vector with a 5D tensor! A 5D vector has only one axis and has five dimensions along its axis, whereas a 5D tensor has five axes (and may have any number of dimensions along each axis). *Dimensionality* can denote either the number of entries along a specific axis (as in the case of our 5D vector) or the number of axes in a tensor (such as a 5D tensor), which can be confusing at times. In the latter case, it’s technically more correct to talk about *a tensor of rank 5* (the rank of a tensor being the number of axes), but the ambiguous notation *5D tensor* is common regardless."]},{"cell_type":"markdown","metadata":{"id":"vzSaCU7VBIKO","colab_type":"text"},"source":["## **Matrices (2D tensors)**"]},{"cell_type":"markdown","metadata":{"id":"tb8EMpZsBK2D","colab_type":"text"},"source":["An array of vectors is a *matrix*, or 2D tensor. A matrix has two axes (often referred to *rows* and *columns*). You can visually interpret a matrix as a rectangular grid of numbers. This is a Numpy matrix:"]},{"cell_type":"code","metadata":{"id":"wk_efbHjBVXB","colab_type":"code","outputId":"7878d649-0ddf-466d-f080-845dee8b4616","executionInfo":{"status":"ok","timestamp":1587701235460,"user_tz":-120,"elapsed":2275,"user":{"displayName":"Robert Haschke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJN0g2mpV0fVJ3Sek5D40HuIwztiXftNdrsw-uaQ=s64","userId":"11038746730354035196"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["x = np.array([[5, 78, 2, 34, 0],\n","              [6, 79, 3, 35, 1],\n","              [7, 80, 4, 36, 2]])\n","\n","x.ndim"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"B12u2XVHBb4E","colab_type":"text"},"source":["The entries from the first axis are called the *rows*, and the entries from the second axis are called the *columns*. In the previous example, $[5, 78, 2, 34, 0]$ is the first row of $x$, and $[5, 6, 7]$ is the first column."]},{"cell_type":"markdown","metadata":{"id":"u8UPrkx1BzL0","colab_type":"text"},"source":["## **3D tensors and higher-dimensional tensors**"]},{"cell_type":"markdown","metadata":{"id":"j9v2_RvjCjiX","colab_type":"text"},"source":["If you pack such matrices in a new array, you obtain a 3D tensor, which you can visually interpret as a cube of numbers. Following is a Numpy 3D tensor:"]},{"cell_type":"code","metadata":{"id":"8SMHc605CoJn","colab_type":"code","outputId":"dd25e105-6b82-41a8-c2dc-5119bad1d744","executionInfo":{"status":"ok","timestamp":1587701235461,"user_tz":-120,"elapsed":2270,"user":{"displayName":"Robert Haschke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJN0g2mpV0fVJ3Sek5D40HuIwztiXftNdrsw-uaQ=s64","userId":"11038746730354035196"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["x = np.array([[[5, 78, 2, 34, 0],\n","               [6, 79, 3, 35, 1],\n","               [7, 80, 4, 36, 2]],\n","              [[5, 78, 2, 34, 0],\n","               [6, 79, 3, 35, 1],\n","               [7, 80, 4, 36, 2]],\n","              [[5, 78, 2, 34, 0],\n","               [6, 79, 3, 35, 1],\n","               [7, 80, 4, 36, 2]]])\n","\n","x.ndim"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"UmA60JqyDg5p","colab_type":"text"},"source":["By packing 3D tensors in an array, you can create a 4D tensor, and so on. In deep learning, you’ll generally manipulate tensors that are 0D to 4D, although you may go up to 5D if you process video data. \n","\n","\n","\n","> Here's a figure visualizing tensors:\n","![tensors](https://res.cloudinary.com/practicaldev/image/fetch/s--VaxrSdrA--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/bp6ux6ppf5t5amwkxklq.jpg)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"S5wlHjtfD_UZ","colab_type":"text"},"source":["## **Key attributes**"]},{"cell_type":"markdown","metadata":{"id":"vsaGAm1_EDc0","colab_type":"text"},"source":["A tensor is defined by three key attributes:\n","\n","- *Number of axes (rank)*—For instance, a 3D tensor has three axes, and a matrix has two axes. This is also called the tensor’s `ndim` in Python libraries such as Numpy.\n","\n","- *Shape*—This is a tuple of integers that describes how many dimensions the tensor has along each axis. For instance, the previous matrix example has shape $(3, 5)$, and the 3D tensor example has shape $(3, 3, 5)$. A vector has a shape with a single element, such as $(5,)$, whereas a scalar has an empty shape, $()$.\n","\n","-  *Data type* (usually called `dtype` in Python libraries)—This is the type of the data contained in the tensor; for instance, a tensor’s type could be `float32`, `uint8`, `float64`, and so on. On rare occasions, you may see a `char` tensor. Note that string tensors don’t exist in Numpy (or in most other libraries), because tensors live in preallocated, contiguous memory segments: and strings, being variable length, would preclude the use of this implementation.\n","\n","\n","> To make this more concrete, let’s look back at the data we processed in the MNIST example. First, we load the MNIST dataset:"]},{"cell_type":"code","metadata":{"id":"_v-gXjmcFS-A","colab_type":"code","outputId":"7c41e6a8-1c9d-4877-936d-e82c78199f7d","executionInfo":{"status":"ok","timestamp":1587701239815,"user_tz":-120,"elapsed":6619,"user":{"displayName":"Robert Haschke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJN0g2mpV0fVJ3Sek5D40HuIwztiXftNdrsw-uaQ=s64","userId":"11038746730354035196"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["from keras.datasets import mnist\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 2s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gufktqi1FlXz","colab_type":"code","outputId":"5ccf8e9a-ef54-4d15-cd8b-3f924ea649dd","executionInfo":{"status":"ok","timestamp":1587701239816,"user_tz":-120,"elapsed":6614,"user":{"displayName":"Robert Haschke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJN0g2mpV0fVJ3Sek5D40HuIwztiXftNdrsw-uaQ=s64","userId":"11038746730354035196"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Next, we display the number of axes of the tensor train_images, the ndim attribute:\n","print(train_images.ndim)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8EkJEg42Fga5","colab_type":"code","outputId":"d764dc1f-5240-48b2-b6fd-d4348b2e9e2d","executionInfo":{"status":"ok","timestamp":1587701239817,"user_tz":-120,"elapsed":6610,"user":{"displayName":"Robert Haschke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJN0g2mpV0fVJ3Sek5D40HuIwztiXftNdrsw-uaQ=s64","userId":"11038746730354035196"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Here's its shape\n","print(train_images.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(60000, 28, 28)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uAdjQV8WFubp","colab_type":"code","outputId":"3e930e89-f6ce-4629-bd85-1bb9e8a5708c","executionInfo":{"status":"ok","timestamp":1587701239817,"user_tz":-120,"elapsed":6604,"user":{"displayName":"Robert Haschke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJN0g2mpV0fVJ3Sek5D40HuIwztiXftNdrsw-uaQ=s64","userId":"11038746730354035196"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# And this is its data type, the dtype attribute:\n","print(train_images.dtype)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["uint8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ToIQsqfoNTU0","colab_type":"text"},"source":["So what we have here is a 3D tensor of 8-bit integers. More precisely, it’s an array of 60,000 matrices of 28 × 28 integers. Each such matrix is a grayscale image, with coefficients between 0 and 255. \n","\n","Let’s display some digits in this 3D tensor, using the library *Matplotlib* (part of the standard scientific Python suite) and let's also use *ipywidgets* to get an interactive output! Feel free to play with the slider to get different samples from `train_images`"]},{"cell_type":"code","metadata":{"id":"0vUDbYL8y1sC","colab_type":"code","outputId":"0361bceb-892a-492c-ee60-4a4ef3a7a105","executionInfo":{"status":"ok","timestamp":1587701239818,"user_tz":-120,"elapsed":6600,"user":{"displayName":"Robert Haschke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJN0g2mpV0fVJ3Sek5D40HuIwztiXftNdrsw-uaQ=s64","userId":"11038746730354035196"}},"colab":{"base_uri":"https://localhost:8080/","height":315,"referenced_widgets":["5292665001f74267b1acf04179610c34","338b70a4f0434947a4fef1f05441b24c","6b1a062e708a4693a25c4f5c1657aad6","d61151c877904c38843926a6d0f9f96f","cc3449aec3c947afa0ecf431ce3d9f29","f35eee3c086c491cb5c999b36dc6aa3f","d1ab6f2a1bae48c4b5582fbed90a27d9"]}},"source":["from ipywidgets import interact\n","import matplotlib.pyplot as plt\n","\n","\n","def plot_digit(n):\n","    plt.imshow(train_images[n], cmap=plt.cm.binary)\n","    plt.show()\n","  \n","# Since we have 60k samples, define the slider size accordingly: (min, max, step)\n","interact(plot_digit, n=(0, 60000, 1))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5292665001f74267b1acf04179610c34","version_minor":0,"version_major":2},"text/plain":["interactive(children=(IntSlider(value=30000, description='n', max=60000), Output()), _dom_classes=('widget-int…"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["<function __main__.plot_digit>"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"8cepbldd-8Ma","colab_type":"text"},"source":["---\n","\n","***Source Alert***\n","\n","- Please open [this notebook](https://colab.research.google.com/github/ageron/handson-ml2/blob/master/tools_matplotlib.ipynb#scrollTo=fFxS6UQsuAAc) for a detailed introduction to [`matplotlib`](https://matplotlib.org), _the_ plotting library for Python, by [Aurélien Geron](https://twitter.com/aureliengeron?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor)\n","\n","- Open this notebook [this notebook](https://colab.research.google.com/notebooks/widgets.ipynb#scrollTo=P6xc9QVFSlrw) for Colab `widgets` and [this notebook](https://colab.research.google.com/notebooks/forms.ipynb#scrollTo=eFN7-fUKs-Bu) to learn more about how Jupyter Widgets can be used in Colab.\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"jpWllIQV-ePH","colab_type":"text"},"source":["## **Manipulating tensors in Numpy**"]},{"cell_type":"markdown","metadata":{"id":"9aYKz_K7-rRz","colab_type":"text"},"source":["In the previous example, we selected a specific digit alongside the first axis using the syntax `train_images[i]`. Selecting specific elements in a tensor is called ***tensor slicing***. Let’s look at the tensor-slicing operations you can do on Numpy arrays.\n","\n","The following example selects digits #10 to #100 (#100 isn’t included) and puts them in an array of shape $(90, 28, 28)$:"]},{"cell_type":"code","metadata":{"id":"b9WoREma-qk4","colab_type":"code","outputId":"b2eb7229-44b6-43f7-c246-97cb178bf7f8","executionInfo":{"status":"ok","timestamp":1587701239818,"user_tz":-120,"elapsed":6597,"user":{"displayName":"Robert Haschke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJN0g2mpV0fVJ3Sek5D40HuIwztiXftNdrsw-uaQ=s64","userId":"11038746730354035196"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["my_slice = train_images[10:100]\n","print(my_slice.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(90, 28, 28)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"F2uSN6fs_Ghm","colab_type":"text"},"source":["It’s equivalent to this more detailed notation, which specifies a *start index* and *stop index* for the slice along each tensor axis. Note that $:$ is equivalent to selecting the entire axis:"]},{"cell_type":"code","metadata":{"id":"8ZdBZvMp_QLr","colab_type":"code","outputId":"1019d262-d81a-40bf-db78-54f30ecebaef","executionInfo":{"status":"ok","timestamp":1587701239819,"user_tz":-120,"elapsed":6595,"user":{"displayName":"Robert Haschke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJN0g2mpV0fVJ3Sek5D40HuIwztiXftNdrsw-uaQ=s64","userId":"11038746730354035196"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Equivalent to the previous example\n","my_slice = train_images[10:100, :, :]\n","my_slice.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(90, 28, 28)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"5m5vbS8G_bKc","colab_type":"code","outputId":"578ce062-8e18-45df-b989-a625050914db","executionInfo":{"status":"ok","timestamp":1587701239819,"user_tz":-120,"elapsed":6591,"user":{"displayName":"Robert Haschke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJN0g2mpV0fVJ3Sek5D40HuIwztiXftNdrsw-uaQ=s64","userId":"11038746730354035196"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Also equivalent to the previous example\n","my_slice = train_images[10:100, 0:28, 0:28]\n","my_slice.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(90, 28, 28)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"2PdNXJeS_kju","colab_type":"text"},"source":[" ## **The notion of data batches**"]},{"cell_type":"markdown","metadata":{"id":"LO9uIdcK_pPq","colab_type":"text"},"source":["In general, the first axis (axis 0, because indexing starts at 0) in all data tensors you’ll come across in deep learning will be the samples axis (sometimes called the samples dimension). In the MNIST example, samples are images of digits.\n","\n","In addition, deep-learning models don’t process an entire dataset at once; rather, they break the data into small ***batches***. Concretely, here’s one batch of our MNIST digits, with batch size of 128:"]},{"cell_type":"code","metadata":{"id":"E4Hti74f_nsv","colab_type":"code","colab":{}},"source":["batch = train_images[:128]\n","\n","# And here's the next batch\n","batch = train_images[128:256]\n","\n","# And the nth batch\n","n = 10\n","batch = train_images[128 * n:128 * (n + 1)]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DtTqM7d-BQjB","colab_type":"text"},"source":["Datasets splitted into individual batches are stored in a so called ***batch tensor***, whose first axis (axis 0) is called the ***batch axis*** or ***batch dimension***. This is a term you’ll frequently encounter when using Keras and other deep-learning libraries."]},{"cell_type":"markdown","metadata":{"id":"hHQfIRCTCXMD","colab_type":"text"},"source":["## **Real-world examples of data tensors**"]},{"cell_type":"markdown","metadata":{"id":"Aw9dVaLcCaZx","colab_type":"text"},"source":["Let’s make data tensors more concrete with a few examples similar to what you’ll encounter later. The data you’ll manipulate will almost always fall into one of the following categories:\n","\n","- *Vector data*—**2D** tensors of shape $(samples, features)$\n","\n","- *Timeseries data* or *sequence data*—**3D** tensors of shape $(samples, timesteps, features)$\n","\n","- *Images*—**4D** tensors of shape $(samples, height, width, channels)$ or $(samples, channels, height, width)$\n","\n","- *Video*—**5D** tensors of shape $(samples, frames, height, width, channels)$ or $(samples, frames, channels, height, width)$"]},{"cell_type":"markdown","metadata":{"id":"Pm-JOp3BEofd","colab_type":"text"},"source":["### Vector data"]},{"cell_type":"markdown","metadata":{"id":"E7e2Tv2VEvFV","colab_type":"text"},"source":["This is the most common case. In such a dataset, each single data point can be encoded as a vector, and thus a batch of data will be encoded as a 2D tensor (that is, an array of vectors), where the first axis is the *samples* axis and the second axis is the *features* axis. \n","\n","Let’s take a look at two examples:\n","\n","- A dataset of text documents, where we represent each document by the counts of how many times each word appears in it (out of a dictionary of 20,000 common words). Each document can be encoded as a vector of 20,000 values (one count per word in the dictionary), and thus an entire dataset of 500 documents can be stored in a tensor of shape $(500, 20000)$."]},{"cell_type":"markdown","metadata":{"id":"nWIoO8UhHDxV","colab_type":"text"},"source":["### Timeseries data or sequence data"]},{"cell_type":"markdown","metadata":{"id":"h8TcitMRHHuv","colab_type":"text"},"source":["Whenever time matters in your data (or the notion of sequence order), it makes sense to store it in a 3D tensor with an explicit time axis. Each sample can be encoded as a sequence of vectors (a 2D tensor), and thus a batch of data will be encoded as a 3D tensor.\n","\n","- A dataset of tweets, where we encode each tweet as a sequence of $280$ characters out of an alphabet of $128$ unique characters. In this setting, each character can be encoded as a binary vector of size $128$ (an all-zeros vector except for a 1 entry at the index corresponding to the character). Then each tweet can be encoded as a 2D tensor of shape $(280, 128)$, and a dataset of 1 million tweets can be stored in a tensor of shape $(1000000, 280, 128)$."]},{"cell_type":"markdown","metadata":{"id":"Axv52B5vMdBm","colab_type":"text"},"source":["### Image data"]},{"cell_type":"markdown","metadata":{"id":"-UXrJY3WMe7B","colab_type":"text"},"source":["Images typically have three dimensions: height, width, and color depth. Although grayscale images (like our MNIST digits) have only a single color channel and could thus be stored in 2D tensors, by convention image tensors are always 3D, with a onedimensional color channel for grayscale images. A batch of $128$ grayscale images of size $256 × 256$ could thus be stored in a tensor of shape $(128, 256, 256, 1)$, and a batch of $128$ color images could be stored in a tensor of shape $(128, 256, 256, 3)$\n","\n","> See the figure: \n","\n","![figure](https://miro.medium.com/max/1276/1*WArDf9h6Dtbo-4H5P4lguQ.png)\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Zr1JaKxJB_QQ","colab_type":"text"},"source":["---\n","# III. Tensor Operations"]},{"cell_type":"markdown","metadata":{"id":"7BKv2i-1nhho","colab_type":"text"},"source":["Much as any computer program can be ultimately reduced to a small set of binary operations on binary inputs (AND, OR, NOR, and so on), all transformations learned by deep neural networks can be reduced to a handful of tensor operations applied to tensors of numeric data. For instance, it’s possible to add tensors, multiply tensors, and so on.\n","\n","In our initial example, we were building our network by stacking $Dense$ layers on top of each other. A Keras layer instance looks like this: \n","\n","> `keras.layers.Dense(512, activation='relu')`\n","\n","This layer can be interpreted as a function, which takes as input a 2D tensor and returns another 2D tensor—a new representation for the input tensor. Specifically, the function is as follows (where W is a 2D tensor and b is a vector, both attributes of the\n","layer):\n","\n","> `output = relu(dot(W, input) + b)`\n","\n","Let’s unpack this. We have three tensor operations here: a dot product ($dot$) between the input tensor and a tensor named $W$; an addition ($+$) between the resulting 2D tensor and a vector $b$; and, finally, a $relu$ operation. $relu(x)$ is $max(x, 0)$. Here's the graph of $relu$:\n","\n","![relu](https://qph.fs.quoracdn.net/main-qimg-d23ac99265ab19599e71c9d1a3cb089a)\n","\n","Here are some other ***activation functions***:\n","![act.fns](https://cdn-images-1.medium.com/max/1000/1*4ZEDRpFuCIpUjNgjDdT2Lg.png)"]},{"cell_type":"markdown","metadata":{"id":"89-waha-4MdJ","colab_type":"text"},"source":["## Element-wise operations"]},{"cell_type":"markdown","metadata":{"id":"t4U656nHpNEv","colab_type":"text"},"source":["The $relu$ operation and addition are element-wise operations: operations that are applied independently to each entry in the tensors being considered. If you want to write a naive Python implementation of an element-wise operation, you use a for loop, as in this naive implementation of an element-wise relu operation:"]},{"cell_type":"code","metadata":{"id":"yEPn8rk5fp0d","colab_type":"code","colab":{}},"source":["def naive_relu(x):\n","  assert len(x.shape) == 2       # x & y are 2D numpy tensors\n","  x = x.copy()                   # Avoid overwriting the input tensor\n","  \n","  for i in range(x.shape[0]):\n","    for j in range(x.shape[1]):\n","      x[i, j] = max(x[i, j], 0)\n","  return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lm3dTuWJfyNV","colab_type":"text"},"source":["You do the same for addition:"]},{"cell_type":"code","metadata":{"id":"9QsS9-czf5nz","colab_type":"code","colab":{}},"source":["def naive_add(x, y):\n","  assert len(x.shape) == 2      # x & y are 2D numpy tensors\n","  assert x.shape == y.shape\n","  x = x.copy()                  # Avoid overwriting the input tensor\n","  \n","  for i in range(x.shape[0]):\n","    for j in range(x.shape[1]):\n","      x[i, j] += y[i, j]\n","  return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5B9U3qCqgA-M","colab_type":"text"},"source":["On the same principle, you can do element-wise multiplication, subtraction, and so on.\n","\n","In practice, when dealing with Numpy arrays, these operations are available as welloptimized built-in Numpy functions. These are low-level, highly parallel, efficient tensor-manipulation\n","routines that are typically implemented in Fortran or C. \n","\n","So, in Numpy, you can do the following element-wise operation, and it will be blazing\n","fast:\n","```python\n","import numpy as np\n","z = x + y                   # --> Element-wise addition\n","z = np.maximum(z, 0.)       # --> Element-wise relu\n","```"]},{"cell_type":"markdown","metadata":{"id":"lJf8-sRq4RBf","colab_type":"text"},"source":["## Tensor dot"]},{"cell_type":"markdown","metadata":{"id":"sxd0UgO5sLvr","colab_type":"text"},"source":["The dot operation, also called a tensor product (not to be confused with an elementwise product) is the most common, most useful tensor operation. Contrary to element-wise operations, it combines entries in the input tensors. An element-wise product is done with the $*$ operator in Numpy, Keras, Theano, and TensorFlow. $dot$ uses a different syntax in TensorFlow, but in both Numpy and Keras it’s done using the standard $dot$ operator:\n","\n","```\n","import numpy as np\n","z = np.dot(x, y)\n","```\n","\n","We know that the dot product between two vectors is a scalar and that only vectors with the same number of elements are compatible for a dot product.\n"]},{"cell_type":"code","metadata":{"id":"UK9gincswXax","colab_type":"code","outputId":"f4efd291-2252-48f2-d523-74db5b908866","executionInfo":{"status":"error","timestamp":1587703637803,"user_tz":-120,"elapsed":923,"user":{"displayName":"Robert Haschke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJN0g2mpV0fVJ3Sek5D40HuIwztiXftNdrsw-uaQ=s64","userId":"11038746730354035196"}},"colab":{"base_uri":"https://localhost:8080/","height":245}},"source":["import numpy as np\n","x = np.array([1,2,3])   # has shape (3,)\n","y = np.array([2,1])     # has shape (2,)\n","np.dot(x,y)             # Will fail due to mismatching shapes"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-5a67467f60b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# has shape (3,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# has shape (2,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m             \u001b[0;31m# Will fail due to mismatching shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: shapes (3,) and (2,) not aligned: 3 (dim 0) != 2 (dim 0)"]}]},{"cell_type":"markdown","metadata":{"id":"skFBPRndw3sT","colab_type":"text"},"source":["You can also take the dot product between a matrix $X$ and a vector $y$, which returns a vector where the coefficients are the dot products between $y$ and the rows of $X$."]},{"cell_type":"code","metadata":{"id":"_97ftgAWwCj9","colab_type":"code","outputId":"9ce817ab-8252-4526-a527-f70d2bfb3f2f","executionInfo":{"status":"ok","timestamp":1587703642922,"user_tz":-120,"elapsed":792,"user":{"displayName":"Robert Haschke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJN0g2mpV0fVJ3Sek5D40HuIwztiXftNdrsw-uaQ=s64","userId":"11038746730354035196"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["X = np.array([[1,2], \n","              [3,4]])    # has shape (2,2)\n","\n","y = np.array([0, 4])     # has shape (2,)\n","np.dot(X,y)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 8, 16])"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"7eWK7O733r-k","colab_type":"text"},"source":["Note that as soon as one of the two tensors has an `ndim` greater than 1, $dot$ is no longer symmetric, which is to say that $dot(x, y)$ isn’t the same as $dot(y, x)$:"]},{"cell_type":"code","metadata":{"id":"AYaNx3CK309L","colab_type":"code","outputId":"17dba5a6-7725-467d-e06b-37f1b4e8e397","executionInfo":{"status":"ok","timestamp":1587703761302,"user_tz":-120,"elapsed":771,"user":{"displayName":"Robert Haschke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJN0g2mpV0fVJ3Sek5D40HuIwztiXftNdrsw-uaQ=s64","userId":"11038746730354035196"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["print(f\"Dot product of X and y: {np.dot(X, y)}\",\n","      f\"\\nDot product of y and X: {np.dot(y, X)} equals dot product of X transposed and y: {np.dot(X.T, y)}\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Dot product of X and y: [ 8 16] \n","Dot product of y and X: [12 16] equals dot product of X transposed and y: [12 16]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AwQNCjhu4Sy1","colab_type":"text"},"source":["Of course, a dot product generalizes to tensors with an arbitrary number of axes. The most common applications may be the dot product between two matrices. You can take the dot product of two matrices $X$ and $Y$ $(dot(X, Y))$ if and only if `X.shape[1] == Y.shape[0]`. The result is a matrix with shape $(X.shape[0],\n","Y.shape[1])$ , where the coefficients are the vector products between the rows of $X$ and the columns of $y$.\n","\n","To understand dot-product shape compatibility, it helps to visualize the input and output tensors by aligning them as shown in the following figure: \n","\n","![tensor-dot](https://4.bp.blogspot.com/-Gt2dGWco0as/XCboOkqfkVI/AAAAAAAAb1w/jh5PcvX-AFY3Zrk1lB7u307t52m7QyaAwCLcBGAs/s1600/%25E3%2582%25B9%25E3%2582%25AF%25E3%2583%25AA%25E3%2583%25BC%25E3%2583%25B3%25E3%2582%25B7%25E3%2583%25A7%25E3%2583%2583%25E3%2583%2588%2B2018-12-29%2B12.21.10.png)\n","\n","\n","More generally, you can take the dot product between higher-dimensional tensors, following the same rules for shape compatibility as outlined earlier for the 2D case:\n","\n","> $(a, b, c, d) . (d,)$ -> $(a, b, c)$\n","\n","> $(a, b, c, d) . (d, e)$ -> $(a, b, c, e)$\n","\n","And so on."]},{"cell_type":"markdown","metadata":{"id":"O59cQILU4Uaa","colab_type":"text"},"source":["## Tensor reshaping"]},{"cell_type":"markdown","metadata":{"id":"cjXq4K1i5GCe","colab_type":"text"},"source":["A third type of tensor operation that’s essential to understand is ***tensor reshaping***. Although it wasn’t used in the Dense layers in our first neural network example, we use it when we preprocess the image data before feeding it into our network:\n","\n","> `train_images = train_images.reshape((60000, 28 * 28))`\n","\n","Reshaping a tensor means rearranging its rows and columns to match a target shape. Naturally, the reshaped tensor has the same total number of coefficients as the initial tensor. Reshaping is best understood via simple examples:"]},{"cell_type":"code","metadata":{"id":"i43EbIsU5Zii","colab_type":"code","outputId":"74cba26e-5a99-44cf-b7fe-f10d3bd6988d","executionInfo":{"status":"ok","timestamp":1587703881852,"user_tz":-120,"elapsed":1008,"user":{"displayName":"Robert Haschke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJN0g2mpV0fVJ3Sek5D40HuIwztiXftNdrsw-uaQ=s64","userId":"11038746730354035196"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["x = np.array([[0., 1.],\n","              [2., 3.],\n","              [4., 5.]])\n","\n","x.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3, 2)"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"BbU00Plc5ez7","colab_type":"code","outputId":"2d96eb29-70da-4ddf-f53b-478b0e70ad5b","executionInfo":{"status":"ok","timestamp":1587703883116,"user_tz":-120,"elapsed":519,"user":{"displayName":"Robert Haschke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJN0g2mpV0fVJ3Sek5D40HuIwztiXftNdrsw-uaQ=s64","userId":"11038746730354035196"}},"colab":{"base_uri":"https://localhost:8080/","height":126}},"source":["x = x.reshape((6, 1))\n","x"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.],\n","       [1.],\n","       [2.],\n","       [3.],\n","       [4.],\n","       [5.]])"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"ZFMbaEc55kGu","colab_type":"code","outputId":"de58e1a8-c8e6-45c8-d1c0-e2b4ad3e3db0","executionInfo":{"status":"ok","timestamp":1587703887848,"user_tz":-120,"elapsed":754,"user":{"displayName":"Robert Haschke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJN0g2mpV0fVJ3Sek5D40HuIwztiXftNdrsw-uaQ=s64","userId":"11038746730354035196"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["x = x.reshape((2, 3))\n","x"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 1., 2.],\n","       [3., 4., 5.]])"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"ksUACAlL5r29","colab_type":"text"},"source":["A special case of reshaping that’s commonly encountered is $transposition$. Transposing a matrix means exchanging its rows and its columns, so that `X[i, :]` becomes `X[:, i]`:"]},{"cell_type":"code","metadata":{"id":"sR9Av8ut5z65","colab_type":"code","colab":{}},"source":["x = np.zeros((300, 20))\n","x.shape"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CZsiOmATh-Ds","colab_type":"text"},"source":["The transposed of this matrix is easily expressed via `x.T`:"]},{"cell_type":"code","metadata":{"id":"y3XVVxmjiGDu","colab_type":"code","colab":{}},"source":["x.T.shape"],"execution_count":0,"outputs":[]}]}