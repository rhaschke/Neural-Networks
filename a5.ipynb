{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming a neural network layer\n",
    "\n",
    "[Keras](https://keras.io) is a high-level deep-learning framework building on top of [TensorFlow](https://www.tensorflow.org). These frameworks follow the _symbol-to-symbol derivatives_ approach, i.e. automatically derive a computational graph to calculate derivatives. You just need to declare your inputs as TensorFlow variables and use TensorFlow operations on them to compute the forward pass.  \n",
    "\n",
    "## Task 5.1\n",
    "\n",
    "Work through the [Keras tutorial on custom layers](https://keras.io/guides/making_new_layers_and_models_via_subclassing) to learn how to create your own neural network layer.  \n",
    "Create a custom Keras layer that computes Gaussian basis functions, i.e. a layer that maps an input vector $\\mathbf x \\in \\mathbb R^n$ onto an output vector $\\mathbf y = f(\\mathbf x) \\in \\mathbb R^m$ as follows:\n",
    "\\begin{align}\n",
    "  f: \\mathbf x \\in \\mathbb R^n \\mapsto \\left[w_i \\exp\\left(-\\frac{\\|\\mathbf x - \\boldsymbol\\mu_i\\|^2}{\\sigma_i^2}\\right)\\right]_{i=1..m} \\in \\mathbb R^m\n",
    "\\end{align}\n",
    "\n",
    "Instead of projecting an input $\\mathbf x$ onto a weight vector $\\mathbf w$ as the standard neuron function $f(\\mathbf x) = \\sigma(\\mathbf w \\cdot \\mathbf x + b)$ does, the Gaussian basis function becomes active (with weight $w_i$) for all inputs $\\mathbf x$ close to a prototype $\\boldsymbol \\mu_i$. This activation quickly decays with increasing distance of $\\mathbf x$ to $\\boldsymbol \\mu_i$. The parameter $\\sigma_i$ controls the width of the Gaussian, i.e. the size of the active region.\n",
    "\n",
    "For efficient tensor-based operations you need to correctly _broadcast_ the tensors for the difference operation: TensorFlow will pass an input matrix of shape `(batch size, input dim)` for $\\mathbf X$, while you will have a matrix of centers $\\boldsymbol \\mu$ of shape `(input dim, #units)`. To correctly [broadcast](https://numpy.org/doc/stable/user/basics.broadcasting.html) them together, you will need Keras' [`expand_dims()`](https://www.tensorflow.org/api_docs/python/tf/keras/backend/expand_dims) function to extend $\\mathbf X$'s shape to `(batch size, input dim, 1)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(3, 5) (5, 2) (3, 5, 2)\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "### dummy example to compute diffs between data X and centers mu\n",
    "X = tf.ones((3, 5))  # input tensor X with batch dimension 3 and data dim N=5\n",
    "mu = tf.ones((5, 2))  # tensor mu with data dim N=5 and 2 units\n",
    "diffs = K.expand_dims(X) - mu  # diffs tensor: 3 x 5 x 2\n",
    "print(X.shape, mu.shape, diffs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5.2\n",
    "\n",
    "Compare the performance of such a Gaussian basis function layer with that of a standard [`Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer on the MNIST dataset.  \n",
    "Hint: Utilize existing tutorials on setting up your first MNIST MLP with Keras, e.g. https://www.tensorflow.org/guide/keras/train_and_evaluate.\n",
    "\n",
    "To achieve decent performance, you want to:\n",
    "- Initialize the centers $\\boldsymbol \\mu_i$ from random data samples $\\mathbf x$ (create a custom [initializer](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/Initializer))\n",
    "- Initialize $\\sigma_i$ to the typical in-class distance between data points.  \n",
    "  Use [`scipy.spatial.distance_matrix`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance_matrix.html) to compute this statistics on a random selection of your input data.  \n",
    "  (Doing it on the full dataset will probably exhaust your memory.)\n",
    "- Initialize $w_i = 1$\n",
    "\n",
    "Questions:\n",
    "- How many parameters each of those networks have?\n",
    "- Which network trains faster / easier?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}